{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObJwZ1pbueS3",
        "outputId": "643c34c6-9172-4bdf-bbdc-8cba4df72d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1VhD_VBvDI2",
        "outputId": "6ecd7966-382d-4f21-9711-5129897eb2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ASR/StyleTokens\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/ASR/StyleTokens/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpgU0I2lvSaA",
        "outputId": "913c7020-3888-44d5-ee0f-7f4b2753d0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.9/dist-packages (0.48.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pypinyin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-aVkD9FvU6E",
        "outputId": "e9d0357c-248f-4d5b-de24-f422517325e9"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "_TvAFoio9V4N",
        "outputId": "9de812d9-4ef9-4229-fa34-e8df76a5bfc0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from GST import GST\n",
        "from Hyperparameters import Hyperparameters as hp\n",
        "\n",
        "\n",
        "class Tacotron(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        texts: [N, T_x]\n",
        "        mels: [N, T_y/r, n_mels*r]\n",
        "    output:\n",
        "        mels --- [N, T_y/r, n_mels*r]\n",
        "        mags --- [N, T_y, 1+n_fft//2]\n",
        "        attn_weights --- [N, T_y/r, T_x]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(len(hp.vocab), hp.E)\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "        self.gst = GST()\n",
        "\n",
        "    def forward(self, texts, mels, ref_mels):\n",
        "        embedded = self.embedding(texts)  # [N, T_x, E]\n",
        "        memory, encoder_hidden = self.encoder(embedded)  # [N, T_x, E]\n",
        "\n",
        "        style_embed = self.gst(ref_mels)  # [N, 256]\n",
        "        style_embed = style_embed.expand_as(memory)\n",
        "        memory = memory + style_embed\n",
        "\n",
        "        mels_hat, mags_hat, attn_weights = self.decoder(mels, memory)\n",
        "\n",
        "        return mels_hat, mags_hat, attn_weights\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        inputs: [N, T_x, E]\n",
        "    output:\n",
        "        outputs: [N, T_x, E]\n",
        "        hidden: [2, N, E//2]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prenet = PreNet(in_features=hp.E)  # [N, T, E//2]\n",
        "\n",
        "        self.conv1d_bank = Conv1dBank(K=hp.K, in_channels=hp.E // 2, out_channels=hp.E // 2)  # [N, T, E//2 * K]\n",
        "\n",
        "        self.conv1d_1 = Conv1d(in_channels=hp.K * hp.E // 2, out_channels=hp.E // 2, kernel_size=3)  # [N, T, E//2]\n",
        "        self.conv1d_2 = Conv1d(in_channels=hp.E // 2, out_channels=hp.E // 2, kernel_size=3)  # [N, T, E//2]\n",
        "        self.bn1 = BatchNorm1d(num_features=hp.E // 2)\n",
        "        self.bn2 = BatchNorm1d(num_features=hp.E // 2)\n",
        "\n",
        "        self.highways = nn.ModuleList()\n",
        "        for i in range(hp.num_highways):\n",
        "            self.highways.append(Highway(in_features=hp.E // 2, out_features=hp.E // 2))\n",
        "\n",
        "        self.gru = nn.GRU(input_size=hp.E // 2, hidden_size=hp.E // 2, num_layers=2, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs, prev_hidden=None):\n",
        "        # prenet\n",
        "        inputs = self.prenet(inputs)  # [N, T, E//2]\n",
        "\n",
        "        # CBHG\n",
        "        # conv1d bank\n",
        "        outputs = self.conv1d_bank(inputs)  # [N, T, E//2 * K]\n",
        "        outputs = max_pool1d(outputs, kernel_size=2)  # [N, T, E//2 * K]\n",
        "\n",
        "        # conv1d projections\n",
        "        outputs = self.conv1d_1(outputs)  # [N, T, E//2]\n",
        "        outputs = self.bn1(outputs)\n",
        "        outputs = nn.functional.relu(outputs)  # [N, T, E//2]\n",
        "        outputs = self.conv1d_2(outputs)  # [N, T, E//2]\n",
        "        outputs = self.bn2(outputs)\n",
        "\n",
        "        outputs = outputs + inputs  # residual connect\n",
        "\n",
        "        # highway\n",
        "        for layer in self.highways:\n",
        "            outputs = layer(outputs)\n",
        "            # outputs = nn.functional.relu(outputs)  # [N, T, E//2]\n",
        "\n",
        "        # outputs = torch.transpose(outputs, 0, 1)  # [T, N, E//2]\n",
        "\n",
        "        self.gru.flatten_parameters()\n",
        "        outputs, hidden = self.gru(outputs, prev_hidden)  # outputs [N, T, E]\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        inputs --- [N, T_y/r, n_mels * r]\n",
        "        memory --- [N, T_x, E]\n",
        "    output:\n",
        "        mels   --- [N, T_y/r, n_mels*r]\n",
        "        mags --- [N, T_y, 1+n_fft//2]\n",
        "        attn_weights --- [N, T_y/r, T_x]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prenet = PreNet(hp.n_mels)\n",
        "        self.attn_rnn = AttentionRNN()\n",
        "        self.attn_projection = nn.Linear(in_features=2 * hp.E, out_features=hp.E)\n",
        "        self.gru1 = nn.GRU(input_size=hp.E, hidden_size=hp.E, batch_first=True, bidirectional=False)\n",
        "        self.gru2 = nn.GRU(input_size=hp.E, hidden_size=hp.E, batch_first=True, bidirectional=False)\n",
        "        self.fc1 = nn.Linear(in_features=hp.E, out_features=hp.n_mels * hp.r)\n",
        "        self.cbhg = DecoderCBHG()  # Deng\n",
        "        self.fc2 = nn.Linear(in_features=hp.E, out_features=1 + (hp.n_fft))  # Deng\n",
        "\n",
        "    def forward(self, inputs, memory):\n",
        "        if self.training:\n",
        "            # prenet\n",
        "            outputs = self.prenet(inputs)  # [N, T_y/r, E//2]\n",
        "\n",
        "            attn_weights, outputs, attn_hidden = self.attn_rnn(outputs, memory)\n",
        "\n",
        "            attn_apply = torch.bmm(attn_weights, memory)  # [N, T_y/r, E]\n",
        "            attn_project = self.attn_projection(torch.cat([attn_apply, outputs], dim=2))  # [N, T_y/r, E]\n",
        "\n",
        "            # GRU1\n",
        "            self.gru1.flatten_parameters()\n",
        "            outputs1, gru1_hidden = self.gru1(attn_project)  # outputs1--[N, T_y/r, E]  gru1_hidden--[1, N, E]\n",
        "            gru_outputs1 = outputs1 + attn_project  # [N, T_y/r, E]\n",
        "            # GRU2\n",
        "            self.gru2.flatten_parameters()\n",
        "            outputs2, gru2_hidden = self.gru2(gru_outputs1)  # outputs2--[N, T_y/r, E]  gru2_hidden--[1, N, E]\n",
        "            gru_outputs2 = outputs2 + gru_outputs1\n",
        "\n",
        "            # generate log melspectrogram\n",
        "            mels = self.fc1(gru_outputs2)  # [N, T_y/r, n_mels*r]\n",
        "\n",
        "            # CBHG\n",
        "            out, cbhg_hidden = self.cbhg(mels)  # out -- [N, T_y, E]\n",
        "\n",
        "            # generate linear spectrogram\n",
        "            mags = self.fc2(out)  # out -- [N, T_y, 1+n_fft//2]\n",
        "\n",
        "            return mels, mags, attn_weights\n",
        "\n",
        "        else:\n",
        "            # inputs = Go_frame  [1, 1, n_mels*r]\n",
        "            attn_hidden = None\n",
        "            gru1_hidden = None\n",
        "            gru2_hidden = None\n",
        "\n",
        "            mels = []\n",
        "            mags = []\n",
        "            attn_weights = []\n",
        "            for i in range(hp.max_Ty):\n",
        "                inputs = self.prenet(inputs)\n",
        "                attn_weight, outputs, attn_hidden = self.attn_rnn(inputs, memory, attn_hidden)\n",
        "                attn_weights.append(attn_weight)  # attn_weight: [1, 1, T_x]\n",
        "                attn_apply = torch.bmm(attn_weight, memory)  # [1, 1, E]\n",
        "                attn_project = self.attn_projection(torch.cat([attn_apply, outputs], dim=-1))  # [1, 1, E]\n",
        "\n",
        "                # GRU1\n",
        "                self.gru1.flatten_parameters()\n",
        "                outputs1, gru1_hidden = self.gru1(attn_project, gru1_hidden)  # outputs1--[1, 1, E]  gru1_hidden--[1, 1, E]\n",
        "                outputs1 = outputs1 + attn_project  # [1, T_y/r, E]\n",
        "                # GRU2\n",
        "                self.gru2.flatten_parameters()\n",
        "                outputs2, gru2_hidden = self.gru2(outputs1, gru2_hidden)  # outputs2--[1, T_y/r, E]  gru2_hidden--[1, 1, E]\n",
        "                outputs2 = outputs2 + outputs1\n",
        "\n",
        "                # generate log melspectrogram\n",
        "                mel = self.fc1(outputs2)  # [1, 1, n_mels*r]\n",
        "                inputs = mel[:, :, -hp.n_mels:]  # get last frame\n",
        "                mels.append(mel)\n",
        "\n",
        "            mels = torch.cat(mels, dim=1)  # [1, max_iter, n_mels*r]\n",
        "            attn_weights = torch.cat(attn_weights, dim=1)  # [1, T, T_x]\n",
        "\n",
        "            out, cbhg_hidden = self.cbhg(mels)\n",
        "            mags = self.fc2(out)\n",
        "\n",
        "            return mels, mags, attn_weights\n",
        "\n",
        "\n",
        "class DecoderCBHG(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        inputs: [N, T/r, n_mels * r]\n",
        "    output:\n",
        "        outputs: [N, T, E]\n",
        "        hidden: [2, N, E//2]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1d_bank = Conv1dBank(K=hp.decoder_K, in_channels=hp.n_mels, out_channels=hp.E // 2)\n",
        "\n",
        "        self.conv1d_1 = Conv1d(in_channels=hp.decoder_K * hp.E // 2, out_channels=hp.E, kernel_size=3)\n",
        "        self.bn1 = BatchNorm1d(hp.E)\n",
        "        self.conv1d_2 = Conv1d(in_channels=hp.E, out_channels=hp.n_mels, kernel_size=3)\n",
        "        self.bn2 = BatchNorm1d(hp.n_mels)\n",
        "\n",
        "        self.highways = nn.ModuleList()\n",
        "        for i in range(hp.num_highways):\n",
        "            self.highways.append(Highway(in_features=hp.n_mels, out_features=hp.n_mels))\n",
        "\n",
        "        self.gru = nn.GRU(input_size=hp.n_mels, hidden_size=hp.E // 2, num_layers=2, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs, prev_hidden=None):\n",
        "        inputs = inputs.view(inputs.size(0), -1, hp.n_mels)  # [N, T, n_mels]\n",
        "\n",
        "        # conv1d bank\n",
        "        outputs = self.conv1d_bank(inputs)  # [N, T, E//2 * K]\n",
        "        outputs = max_pool1d(outputs, kernel_size=2)\n",
        "\n",
        "        # conv1d projections\n",
        "        outputs = self.conv1d_1(outputs)  # [N, T, E]\n",
        "        outputs = self.bn1(outputs)\n",
        "        outputs = nn.functional.relu(outputs)\n",
        "        outputs = self.conv1d_2(outputs)  # [N, T, n_mels]\n",
        "        outputs = self.bn2(outputs)\n",
        "\n",
        "        outputs = outputs + inputs  # residual connect  [N, T, n_mels]\n",
        "\n",
        "        # highway net\n",
        "        for layer in self.highways:\n",
        "            outputs = layer(outputs)  # [N, T, n_mels]\n",
        "\n",
        "        # bidirection gru\n",
        "        self.gru.flatten_parameters()\n",
        "        outputs, hidden = self.gru(outputs, prev_hidden)  # outputs: [N, T, E]\n",
        "\n",
        "        return outputs, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WJFZ1AzJvabO"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from Data import get_eval_data\n",
        "from Hyperparameters import Hyperparameters as hp\n",
        "import torch\n",
        "from scipy.io.wavfile import write\n",
        "from Network import *\n",
        "import librosa\n",
        "from pypinyin import lazy_pinyin, Style\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "import librosa\n",
        "import copy\n",
        "import matplotlib\n",
        "matplotlib.use('pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import os\n",
        "\n",
        "device = torch.device('cpu')\n",
        "\n",
        "def spectrogram2wav(mag):\n",
        "    '''# Generate wave file from spectrogram'''\n",
        "    # transpose\n",
        "    #print(mag.shape, \"Mag shape\")\n",
        "    mag = mag.T\n",
        "\n",
        "    # de-noramlize\n",
        "    mag = (np.clip(mag, 0, 1) * hp.max_db) - hp.max_db + hp.ref_db\n",
        "\n",
        "    # to amplitude\n",
        "    mag = np.power(10.0, mag * 0.05)\n",
        "\n",
        "    # wav reconstruction\n",
        "    wav = griffin_lim(mag)\n",
        "\n",
        "    # de-preemphasis\n",
        "    wav = signal.lfilter([1], [1, -hp.preemphasis], wav)\n",
        "\n",
        "    # trim\n",
        "    wav, _ = librosa.effects.trim(wav)\n",
        "    #print(mag.shape)\n",
        "    return wav.astype(np.float32)\n",
        "\n",
        "\n",
        "def griffin_lim(spectrogram):\n",
        "    '''Applies Griffin-Lim's raw.\n",
        "    '''\n",
        "    X_best = copy.deepcopy(spectrogram)\n",
        "    for i in range(hp.n_iter):\n",
        "        X_t = invert_spectrogram(X_best)\n",
        "        est = librosa.stft(X_t, 2*hp.n_fft, hp.hop_length, win_length=hp.win_length)\n",
        "        #print(est.shape, \"Est shape\")\n",
        "        phase = est / np.maximum(1e-8, np.abs(est))\n",
        "        #print(phase.shape, \"Phase shape\")\n",
        "        X_best = spectrogram * phase\n",
        "    X_t = invert_spectrogram(X_best)\n",
        "    y = np.real(X_t)\n",
        "\n",
        "    return y\n",
        "\n",
        "def invert_spectrogram(spectrogram):\n",
        "    '''\n",
        "    spectrogram: [f, t]\n",
        "    '''\n",
        "    return librosa.istft(spectrogram, hp.hop_length, win_length=hp.win_length, window=\"hann\")\n",
        "\n",
        "def synthesis(model, eval_text):\n",
        "    eval_text = _pinyin(eval_text)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # ref_wavs = [\n",
        "    #     'ref_wav/nannan.wav', 'ref_wav/xiaofeng.wav', 'ref_wav/donaldduck.wav'\n",
        "    # ]\n",
        "    ref_wavs = [\n",
        "        'ref_wav/nannan.wav',\n",
        "        'ref_wav/xiaofeng.wav',\n",
        "        'ref_wav/donaldduck.wav'\n",
        "    ]\n",
        "    speakers = ['nannan', 'xiaofeng', 'donaldduck']\n",
        "\n",
        "    wavs = {}\n",
        "\n",
        "    for ref_wav, speaker in zip(ref_wavs, speakers):\n",
        "        text, GO, ref_mels = get_eval_data(eval_text, ref_wav)\n",
        "        text = text.to(device)\n",
        "        GO = GO.to(device)\n",
        "        ref_mels = ref_mels.to(device)\n",
        "\n",
        "        mel_hat, mag_hat, attn = model(text, GO, ref_mels)\n",
        "        mag_hat = mag_hat.squeeze().detach().cpu().numpy()\n",
        "        attn = attn.squeeze().detach().cpu().numpy()\n",
        "        #print(mag_hat.shape)\n",
        "        wav_hat = spectrogram2wav(mag_hat)\n",
        "        wavs[speaker] = wav_hat\n",
        "\n",
        "    return wavs\n",
        "\n",
        "\n",
        "def load_model(checkpoint_path):\n",
        "    model = Tacotron().to(device)\n",
        "    model.load_state_dict(\n",
        "        torch.load(\n",
        "            checkpoint_path, map_location=lambda storage, location: storage))\n",
        "    return model\n",
        "\n",
        "\n",
        "def _pinyin(s):\n",
        "    symbols = '0123456789abcdefghijklmnopqrstuvwxyz '\n",
        "    s = lazy_pinyin(s, style=Style.TONE2)\n",
        "    yin = []\n",
        "    for token in s:\n",
        "        if token != ' ':\n",
        "            a = ''\n",
        "            for c in token:\n",
        "                if c in symbols:\n",
        "                    a += c\n",
        "            yin.append(a)\n",
        "    a = ''\n",
        "    s = ' '.join(yin)\n",
        "    for i in range(len(s)):\n",
        "        if s[i] == ' ' and i < len(s) - 1 and s[i + 1] == ' ':\n",
        "            continue\n",
        "        a += s[i]\n",
        "    return a\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5NRq7U6vdX9"
      },
      "outputs": [],
      "source": [
        "text = '''毛主席是中国的红太阳'''\n",
        "text = \"刘易斯汉密尔顿赢得摩纳哥大奖赛\"\n",
        "text = \"太阳从东方升起\"\n",
        "model = load_model('checkpoint/epoch100.pt')\n",
        "wavs = synthesis(model, text)\n",
        "for k in wavs:\n",
        "  wav = wavs[k]\n",
        "  write('samples/{}.wav'.format(k), hp.sr, wav)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
