{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObJwZ1pbueS3",
        "outputId": "643c34c6-9172-4bdf-bbdc-8cba4df72d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ASR/StyleTokens/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1VhD_VBvDI2",
        "outputId": "6ecd7966-382d-4f21-9711-5129897eb2e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASR/StyleTokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypinyin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpgU0I2lvSaA",
        "outputId": "913c7020-3888-44d5-ee0f-7f4b2753d0ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.9/dist-packages (0.48.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-aVkD9FvU6E",
        "outputId": "e9d0357c-248f-4d5b-de24-f422517325e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting audioread==2.1.5\n",
            "  Using cached audioread-2.1.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bypy==1.6.4\n",
            "  Using cached bypy-1.6.4-py2.py3-none-any.whl (239 kB)\n",
            "Collecting certifi==2018.4.16\n",
            "  Using cached certifi-2018.4.16-py2.py3-none-any.whl (150 kB)\n",
            "Collecting chardet==3.0.4\n",
            "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting cymem==1.31.2\n",
            "  Using cached cymem-1.31.2.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cytoolz==0.8.2\n",
            "  Using cached cytoolz-0.8.2.tar.gz (386 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decorator==4.3.0\n",
            "  Using cached decorator-4.3.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting dill==0.2.7.1\n",
            "  Using cached dill-0.2.7.1.tar.gz (64 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting idna==2.6\n",
            "  Using cached idna-2.6-py2.py3-none-any.whl (56 kB)\n",
            "Collecting inflect==0.3.1\n",
            "  Using cached inflect-0.3.1-py2.py3-none-any.whl (59 kB)\n",
            "Collecting joblib==0.11\n",
            "  Using cached joblib-0.11-py2.py3-none-any.whl (176 kB)\n",
            "Collecting kiwisolver==1.0.1\n",
            "  Using cached kiwisolver-1.0.1.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting librosa==0.6.0\n",
            "  Using cached librosa-0.6.0.tar.gz (1.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite==0.23.0\n",
            "  Using cached llvmlite-0.23.0.tar.gz (98 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib==2.2.2\n",
            "  Using cached matplotlib-2.2.2.tar.gz (37.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting msgpack-numpy==0.4.1\n",
            "  Using cached msgpack_numpy-0.4.1-py2.py3-none-any.whl (7.0 kB)\n",
            "Collecting msgpack-python==0.5.6\n",
            "  Using cached msgpack-python-0.5.6.tar.gz (138 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting multiprocess==0.70.5\n",
            "  Using cached multiprocess-0.70.5.zip (1.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from GST import GST\n",
        "from Hyperparameters import Hyperparameters as hp\n",
        "\n",
        "\n",
        "class Tacotron(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        texts: [N, T_x]\n",
        "        mels: [N, T_y/r, n_mels*r]\n",
        "    output:\n",
        "        mels --- [N, T_y/r, n_mels*r]\n",
        "        mags --- [N, T_y, 1+n_fft//2]\n",
        "        attn_weights --- [N, T_y/r, T_x]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(len(hp.vocab), hp.E)\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "        self.gst = GST()\n",
        "\n",
        "    def forward(self, texts, mels, ref_mels):\n",
        "        embedded = self.embedding(texts)  # [N, T_x, E]\n",
        "        memory, encoder_hidden = self.encoder(embedded)  # [N, T_x, E]\n",
        "\n",
        "        style_embed = self.gst(ref_mels)  # [N, 256]\n",
        "        style_embed = style_embed.expand_as(memory)\n",
        "        memory = memory + style_embed\n",
        "\n",
        "        mels_hat, mags_hat, attn_weights = self.decoder(mels, memory)\n",
        "\n",
        "        return mels_hat, mags_hat, attn_weights\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        inputs: [N, T_x, E]\n",
        "    output:\n",
        "        outputs: [N, T_x, E]\n",
        "        hidden: [2, N, E//2]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prenet = PreNet(in_features=hp.E)  # [N, T, E//2]\n",
        "\n",
        "        self.conv1d_bank = Conv1dBank(K=hp.K, in_channels=hp.E // 2, out_channels=hp.E // 2)  # [N, T, E//2 * K]\n",
        "\n",
        "        self.conv1d_1 = Conv1d(in_channels=hp.K * hp.E // 2, out_channels=hp.E // 2, kernel_size=3)  # [N, T, E//2]\n",
        "        self.conv1d_2 = Conv1d(in_channels=hp.E // 2, out_channels=hp.E // 2, kernel_size=3)  # [N, T, E//2]\n",
        "        self.bn1 = BatchNorm1d(num_features=hp.E // 2)\n",
        "        self.bn2 = BatchNorm1d(num_features=hp.E // 2)\n",
        "\n",
        "        self.highways = nn.ModuleList()\n",
        "        for i in range(hp.num_highways):\n",
        "            self.highways.append(Highway(in_features=hp.E // 2, out_features=hp.E // 2))\n",
        "\n",
        "        self.gru = nn.GRU(input_size=hp.E // 2, hidden_size=hp.E // 2, num_layers=2, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs, prev_hidden=None):\n",
        "        # prenet\n",
        "        inputs = self.prenet(inputs)  # [N, T, E//2]\n",
        "\n",
        "        # CBHG\n",
        "        # conv1d bank\n",
        "        outputs = self.conv1d_bank(inputs)  # [N, T, E//2 * K]\n",
        "        outputs = max_pool1d(outputs, kernel_size=2)  # [N, T, E//2 * K]\n",
        "\n",
        "        # conv1d projections\n",
        "        outputs = self.conv1d_1(outputs)  # [N, T, E//2]\n",
        "        outputs = self.bn1(outputs)\n",
        "        outputs = nn.functional.relu(outputs)  # [N, T, E//2]\n",
        "        outputs = self.conv1d_2(outputs)  # [N, T, E//2]\n",
        "        outputs = self.bn2(outputs)\n",
        "\n",
        "        outputs = outputs + inputs  # residual connect\n",
        "\n",
        "        # highway\n",
        "        for layer in self.highways:\n",
        "            outputs = layer(outputs)\n",
        "            # outputs = nn.functional.relu(outputs)  # [N, T, E//2]\n",
        "\n",
        "        # outputs = torch.transpose(outputs, 0, 1)  # [T, N, E//2]\n",
        "\n",
        "        self.gru.flatten_parameters()\n",
        "        outputs, hidden = self.gru(outputs, prev_hidden)  # outputs [N, T, E]\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        inputs --- [N, T_y/r, n_mels * r]\n",
        "        memory --- [N, T_x, E]\n",
        "    output:\n",
        "        mels   --- [N, T_y/r, n_mels*r]\n",
        "        mags --- [N, T_y, 1+n_fft//2]\n",
        "        attn_weights --- [N, T_y/r, T_x]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prenet = PreNet(hp.n_mels)\n",
        "        self.attn_rnn = AttentionRNN()\n",
        "        self.attn_projection = nn.Linear(in_features=2 * hp.E, out_features=hp.E)\n",
        "        self.gru1 = nn.GRU(input_size=hp.E, hidden_size=hp.E, batch_first=True, bidirectional=False)\n",
        "        self.gru2 = nn.GRU(input_size=hp.E, hidden_size=hp.E, batch_first=True, bidirectional=False)\n",
        "        self.fc1 = nn.Linear(in_features=hp.E, out_features=hp.n_mels * hp.r)\n",
        "        self.cbhg = DecoderCBHG()  # Deng\n",
        "        self.fc2 = nn.Linear(in_features=hp.E, out_features=1 + (hp.n_fft))  # Deng\n",
        "\n",
        "    def forward(self, inputs, memory):\n",
        "        if self.training:\n",
        "            # prenet\n",
        "            outputs = self.prenet(inputs)  # [N, T_y/r, E//2]\n",
        "\n",
        "            attn_weights, outputs, attn_hidden = self.attn_rnn(outputs, memory)\n",
        "\n",
        "            attn_apply = torch.bmm(attn_weights, memory)  # [N, T_y/r, E]\n",
        "            attn_project = self.attn_projection(torch.cat([attn_apply, outputs], dim=2))  # [N, T_y/r, E]\n",
        "\n",
        "            # GRU1\n",
        "            self.gru1.flatten_parameters()\n",
        "            outputs1, gru1_hidden = self.gru1(attn_project)  # outputs1--[N, T_y/r, E]  gru1_hidden--[1, N, E]\n",
        "            gru_outputs1 = outputs1 + attn_project  # [N, T_y/r, E]\n",
        "            # GRU2\n",
        "            self.gru2.flatten_parameters()\n",
        "            outputs2, gru2_hidden = self.gru2(gru_outputs1)  # outputs2--[N, T_y/r, E]  gru2_hidden--[1, N, E]\n",
        "            gru_outputs2 = outputs2 + gru_outputs1\n",
        "\n",
        "            # generate log melspectrogram\n",
        "            mels = self.fc1(gru_outputs2)  # [N, T_y/r, n_mels*r]\n",
        "\n",
        "            # CBHG\n",
        "            out, cbhg_hidden = self.cbhg(mels)  # out -- [N, T_y, E]\n",
        "\n",
        "            # generate linear spectrogram\n",
        "            mags = self.fc2(out)  # out -- [N, T_y, 1+n_fft//2]\n",
        "\n",
        "            return mels, mags, attn_weights\n",
        "\n",
        "        else:\n",
        "            # inputs = Go_frame  [1, 1, n_mels*r]\n",
        "            attn_hidden = None\n",
        "            gru1_hidden = None\n",
        "            gru2_hidden = None\n",
        "\n",
        "            mels = []\n",
        "            mags = []\n",
        "            attn_weights = []\n",
        "            for i in range(hp.max_Ty):\n",
        "                inputs = self.prenet(inputs)\n",
        "                attn_weight, outputs, attn_hidden = self.attn_rnn(inputs, memory, attn_hidden)\n",
        "                attn_weights.append(attn_weight)  # attn_weight: [1, 1, T_x]\n",
        "                attn_apply = torch.bmm(attn_weight, memory)  # [1, 1, E]\n",
        "                attn_project = self.attn_projection(torch.cat([attn_apply, outputs], dim=-1))  # [1, 1, E]\n",
        "\n",
        "                # GRU1\n",
        "                self.gru1.flatten_parameters()\n",
        "                outputs1, gru1_hidden = self.gru1(attn_project, gru1_hidden)  # outputs1--[1, 1, E]  gru1_hidden--[1, 1, E]\n",
        "                outputs1 = outputs1 + attn_project  # [1, T_y/r, E]\n",
        "                # GRU2\n",
        "                self.gru2.flatten_parameters()\n",
        "                outputs2, gru2_hidden = self.gru2(outputs1, gru2_hidden)  # outputs2--[1, T_y/r, E]  gru2_hidden--[1, 1, E]\n",
        "                outputs2 = outputs2 + outputs1\n",
        "\n",
        "                # generate log melspectrogram\n",
        "                mel = self.fc1(outputs2)  # [1, 1, n_mels*r]\n",
        "                inputs = mel[:, :, -hp.n_mels:]  # get last frame\n",
        "                mels.append(mel)\n",
        "\n",
        "            mels = torch.cat(mels, dim=1)  # [1, max_iter, n_mels*r]\n",
        "            attn_weights = torch.cat(attn_weights, dim=1)  # [1, T, T_x]\n",
        "\n",
        "            out, cbhg_hidden = self.cbhg(mels)\n",
        "            mags = self.fc2(out)\n",
        "\n",
        "            return mels, mags, attn_weights\n",
        "\n",
        "\n",
        "class DecoderCBHG(nn.Module):\n",
        "    '''\n",
        "    input:\n",
        "        inputs: [N, T/r, n_mels * r]\n",
        "    output:\n",
        "        outputs: [N, T, E]\n",
        "        hidden: [2, N, E//2]\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1d_bank = Conv1dBank(K=hp.decoder_K, in_channels=hp.n_mels, out_channels=hp.E // 2)\n",
        "\n",
        "        self.conv1d_1 = Conv1d(in_channels=hp.decoder_K * hp.E // 2, out_channels=hp.E, kernel_size=3)\n",
        "        self.bn1 = BatchNorm1d(hp.E)\n",
        "        self.conv1d_2 = Conv1d(in_channels=hp.E, out_channels=hp.n_mels, kernel_size=3)\n",
        "        self.bn2 = BatchNorm1d(hp.n_mels)\n",
        "\n",
        "        self.highways = nn.ModuleList()\n",
        "        for i in range(hp.num_highways):\n",
        "            self.highways.append(Highway(in_features=hp.n_mels, out_features=hp.n_mels))\n",
        "\n",
        "        self.gru = nn.GRU(input_size=hp.n_mels, hidden_size=hp.E // 2, num_layers=2, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs, prev_hidden=None):\n",
        "        inputs = inputs.view(inputs.size(0), -1, hp.n_mels)  # [N, T, n_mels]\n",
        "\n",
        "        # conv1d bank\n",
        "        outputs = self.conv1d_bank(inputs)  # [N, T, E//2 * K]\n",
        "        outputs = max_pool1d(outputs, kernel_size=2)\n",
        "\n",
        "        # conv1d projections\n",
        "        outputs = self.conv1d_1(outputs)  # [N, T, E]\n",
        "        outputs = self.bn1(outputs)\n",
        "        outputs = nn.functional.relu(outputs)\n",
        "        outputs = self.conv1d_2(outputs)  # [N, T, n_mels]\n",
        "        outputs = self.bn2(outputs)\n",
        "\n",
        "        outputs = outputs + inputs  # residual connect  [N, T, n_mels]\n",
        "\n",
        "        # highway net\n",
        "        for layer in self.highways:\n",
        "            outputs = layer(outputs)  # [N, T, n_mels]\n",
        "\n",
        "        # bidirection gru\n",
        "        self.gru.flatten_parameters()\n",
        "        outputs, hidden = self.gru(outputs, prev_hidden)  # outputs: [N, T, E]\n",
        "\n",
        "        return outputs, hidden\n"
      ],
      "metadata": {
        "id": "_TvAFoio9V4N",
        "outputId": "9de812d9-4ef9-4229-fa34-e8df76a5bfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-eae52ae1ced6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mGST\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mHyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparameters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GST'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "from Data import get_eval_data\n",
        "from Hyperparameters import Hyperparameters as hp\n",
        "import torch\n",
        "from scipy.io.wavfile import write\n",
        "from Network import *\n",
        "import librosa\n",
        "from pypinyin import lazy_pinyin, Style\n",
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "import librosa\n",
        "import copy\n",
        "import matplotlib\n",
        "matplotlib.use('pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import os\n",
        "\n",
        "device = torch.device('cpu')\n",
        "\n",
        "def spectrogram2wav(mag):\n",
        "    '''# Generate wave file from spectrogram'''\n",
        "    # transpose\n",
        "    #print(mag.shape, \"Mag shape\")\n",
        "    mag = mag.T\n",
        "\n",
        "    # de-noramlize\n",
        "    mag = (np.clip(mag, 0, 1) * hp.max_db) - hp.max_db + hp.ref_db\n",
        "\n",
        "    # to amplitude\n",
        "    mag = np.power(10.0, mag * 0.05)\n",
        "\n",
        "    # wav reconstruction\n",
        "    wav = griffin_lim(mag)\n",
        "\n",
        "    # de-preemphasis\n",
        "    wav = signal.lfilter([1], [1, -hp.preemphasis], wav)\n",
        "\n",
        "    # trim\n",
        "    wav, _ = librosa.effects.trim(wav)\n",
        "    #print(mag.shape)\n",
        "    return wav.astype(np.float32)\n",
        "\n",
        "\n",
        "def griffin_lim(spectrogram):\n",
        "    '''Applies Griffin-Lim's raw.\n",
        "    '''\n",
        "    X_best = copy.deepcopy(spectrogram)\n",
        "    for i in range(hp.n_iter):\n",
        "        X_t = invert_spectrogram(X_best)\n",
        "        est = librosa.stft(X_t, 2*hp.n_fft, hp.hop_length, win_length=hp.win_length)\n",
        "        #print(est.shape, \"Est shape\")\n",
        "        phase = est / np.maximum(1e-8, np.abs(est))\n",
        "        #print(phase.shape, \"Phase shape\")\n",
        "        X_best = spectrogram * phase\n",
        "    X_t = invert_spectrogram(X_best)\n",
        "    y = np.real(X_t)\n",
        "\n",
        "    return y\n",
        "\n",
        "def invert_spectrogram(spectrogram):\n",
        "    '''\n",
        "    spectrogram: [f, t]\n",
        "    '''\n",
        "    return librosa.istft(spectrogram, hp.hop_length, win_length=hp.win_length, window=\"hann\")\n",
        "\n",
        "def synthesis(model, eval_text):\n",
        "    eval_text = _pinyin(eval_text)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # ref_wavs = [\n",
        "    #     'ref_wav/nannan.wav', 'ref_wav/xiaofeng.wav', 'ref_wav/donaldduck.wav'\n",
        "    # ]\n",
        "    ref_wavs = [\n",
        "        'ref_wav/nannan.wav',\n",
        "        'ref_wav/xiaofeng.wav',\n",
        "        'ref_wav/donaldduck.wav'\n",
        "    ]\n",
        "    speakers = ['nannan', 'xiaofeng', 'donaldduck']\n",
        "\n",
        "    wavs = {}\n",
        "\n",
        "    for ref_wav, speaker in zip(ref_wavs, speakers):\n",
        "        text, GO, ref_mels = get_eval_data(eval_text, ref_wav)\n",
        "        text = text.to(device)\n",
        "        GO = GO.to(device)\n",
        "        ref_mels = ref_mels.to(device)\n",
        "\n",
        "        mel_hat, mag_hat, attn = model(text, GO, ref_mels)\n",
        "        mag_hat = mag_hat.squeeze().detach().cpu().numpy()\n",
        "        attn = attn.squeeze().detach().cpu().numpy()\n",
        "        #print(mag_hat.shape)\n",
        "        wav_hat = spectrogram2wav(mag_hat)\n",
        "        wavs[speaker] = wav_hat\n",
        "\n",
        "    return wavs\n",
        "\n",
        "\n",
        "def load_model(checkpoint_path):\n",
        "    model = Tacotron().to(device)\n",
        "    model.load_state_dict(\n",
        "        torch.load(\n",
        "            checkpoint_path, map_location=lambda storage, location: storage))\n",
        "    return model\n",
        "\n",
        "\n",
        "def _pinyin(s):\n",
        "    symbols = '0123456789abcdefghijklmnopqrstuvwxyz '\n",
        "    s = lazy_pinyin(s, style=Style.TONE2)\n",
        "    yin = []\n",
        "    for token in s:\n",
        "        if token != ' ':\n",
        "            a = ''\n",
        "            for c in token:\n",
        "                if c in symbols:\n",
        "                    a += c\n",
        "            yin.append(a)\n",
        "    a = ''\n",
        "    s = ' '.join(yin)\n",
        "    for i in range(len(s)):\n",
        "        if s[i] == ' ' and i < len(s) - 1 and s[i + 1] == ' ':\n",
        "            continue\n",
        "        a += s[i]\n",
        "    return a\n",
        "\n"
      ],
      "metadata": {
        "id": "WJFZ1AzJvabO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''毛主席是中国的红太阳'''\n",
        "text = \"刘易斯汉密尔顿赢得摩纳哥大奖赛\"\n",
        "text = \"太阳从东方升起\"\n",
        "model = load_model('checkpoint/epoch100.pt')\n",
        "wavs = synthesis(model, text)\n",
        "for k in wavs:\n",
        "  wav = wavs[k]\n",
        "  write('samples/{}.wav'.format(k), hp.sr, wav)"
      ],
      "metadata": {
        "id": "t5NRq7U6vdX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}